{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TFRecords\n",
    "\n",
    "This notebook is used to create the tfrecords file from the datasets. It is a important step to speed up the training and evaluation time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import modules and define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataset path\n",
    "DATASET_PATH = './UCM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create tfrecords files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and resize images in RGB\n",
    "def imread(path_image, resize=(256,256)):\n",
    "    image = cv2.imread(str(path_image))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, resize)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a bytes_list from a string / byte\n",
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.tobytes()]))\n",
    "\n",
    "# serialize input data\n",
    "def serialize_example(image, label):\n",
    "    feature = {\n",
    "      'image': _bytes_feature(image),\n",
    "      'label': _bytes_feature(label),\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the labels names into numeric values\n",
    "labels_name = glob(os.path.join(DATASET_PATH, '*'))\n",
    "map_ann = {lab:i for i,lab in enumerate(labels_name)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all images in the folders\n",
    "path_images = glob(os.path.join(DATASET_PATH, '**', '*.*'), recursive=True)\n",
    "np.random.shuffle(path_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save tfrecords\n",
    "tfrecords_path = DATASET_PATH+'_tfrecords'\n",
    "size_record = 1\n",
    "total_data  = len(path_images)\n",
    "\n",
    "pbar = tqdm(range(total_data))\n",
    "for i in range(total_data//size_record+1):\n",
    "\n",
    "    with tf.io.TFRecordWriter(os.path.join(tfrecords_path, f'{i}.tfrec'), \\\n",
    "                              options=tf.io.TFRecordOptions(compression_type='GZIP')) as writer:\n",
    "        for k in range(size_record):\n",
    "            if i*size_record+k>=total_data:\n",
    "                break\n",
    "            \n",
    "            img = imread(path_images[i*size_record+k])\n",
    "            label = os.path.split(path_images[i*size_record+k])[0]\n",
    "            label = tf.keras.utils.to_categorical(map_ann[label], len(map_ann))\n",
    "\n",
    "            example = serialize_example(img, label)\n",
    "            writer.write(example)\n",
    "            \n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) 3. Evaluate tfrecords data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to read the tfrecords data\n",
    "def __read_data(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = tf.reshape(tf.io.decode_raw(example['image'], tf.uint8), (256,256,3))\n",
    "    label = tf.reshape(tf.io.decode_raw(example['label'], tf.float32), (len(map_ann),))\n",
    "    return image, label\n",
    "\n",
    "ignore_order = tf.data.Options()\n",
    "ignore_order.experimental_deterministic = False\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(tf.io.gfile.glob(os.path.join(tfrecords_path, '*.tfrec')),\\\n",
    "                                  compression_type='GZIP',\\\n",
    "                                  num_parallel_reads=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.map(__read_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the number of samples for each class (original dataset)\n",
    "{lab:len(os.listdir(lab)) for i,lab in enumerate(labels_name)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the number of samples for each class (tfrecords dataset)\n",
    "ally = [np.argmax(y) for x,y in iter(dataset)]\n",
    "\n",
    "unique, counts = np.unique(ally, return_counts=True)\n",
    "list(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
